---
layout: post
title: High dimensional probability 
author: "Karthik"
categories: journal
tags: [documentation,sample]
---

**Ref**: Prof. Vershynin's [handwritten notes](https://www.math.uci.edu/~rvershyn/teaching/hdp/hdp.html)

**Lec-1**: 

Consider the problem of numerically computing the integral of an ${ f : [0,1] ^d \to \mathbb{R} }.$ 

Breaking ${ [0,1] ^d }$ into (axis aligned) cubes of width ${ \epsilon },$ there are about ${ N \approx (\frac{1}{\epsilon}) ^{d} }$ many such smaller cubes. Now the integral ${ \int _{[0,1] ^d} f(x) dx \approx \frac{1}{N} \sum _{1} ^{N} f(x _i) }$ where the ${ N }$ many ${ x _i }$s are each points from the ${ N }$ smaller cubes. 

In the Monte-Carlo method, instead of having ${ x _i }$s taken from the smaller cubes, they are considered as random variables ${ X _1, \ldots, X _N \stackrel{iid}{\sim} \text{Unif}[0,1] ^d }$ and the random variable ${ \frac{1}{N} \sum _{1} ^{N} f(X _i) }$ approximates (i.e. is an estimator of) ${ \int _{[0,1] ^d} f (x) dx }.$   
Notice expectation ${ \mathbb{E}[\frac{1}{N} \sum _{1} ^{N} f (X _i)] }$ ${ = \mathbb{E}[f(X)] = \int _{[0,1] ^d} f(x) dx }$ where ${ X \sim \text{Unif}[0,1]  ^{d} }.$ Also, the mean squared error ${ \mathbb{E}[ \left( \frac{1}{N} \sum _{1} ^{N} f(X _i) - \int _{[0,1] ^d} f(x) dx \right) ^2]  }$ ${ = \text{var} \left( \frac{1}{N} \sum _{1} ^{N} f (X _i) \right) }$ ${ = \frac{1}{N ^2} \text{var}(\sum _{1} ^{N} f (X _i) ) }$ ${ = \frac{1}{N} \text{var}(f(X)) },$ which is ${ \leq \frac{1}{N} \int f ^{2} (X) dx }$ ${ \leq \frac{1}{N} \lVert f \rVert _{\infty} ^{2} }.$ So standard deviation (root of mean squared error) of the estimator is ${ O(\frac{1}{\sqrt{N}}) }.$ 

**Lec-2**: 

A set ${ T \subseteq \mathbb{R} ^d }$ is convex if for all ${ x, y \in T }$ the segment ${ [x,y] = \lbrace x + t(y-x) : t \in [0,1] \rbrace \subseteq T }.$

Intersection of any family of convex sets is convex. For ${ T \subseteq \mathbb{R} ^d }$ its convex hull is ${ \text{conv}(T) = \cap \lbrace \text{convex sets containing } T \rbrace }$ (the smallest convex set containing ${ T }$).  

Obs: Let ${ T \subseteq \mathbb{R} ^d }.$ Now ${ \text{conv}(T) = \lbrace \text{convex combinations of } z _1, \ldots, z _n \in T \text{ for } n \in \mathbb{Z} _{> 0} \rbrace }$   
(A convex combination of ${ z _1, \ldots, z _n \in \mathbb{R} ^d }$ is an expression of the form ${ \sum _{1} ^{n} \lambda _i z _i }$ where ${ \lambda _i \geq 0, \sum _{1} ^{n} \lambda _i = 1 }$)   
Sketch: For the ${ T }$ finite case, that ${ \text{conv}(\lbrace p _1, \ldots, p _n \rbrace) = \lbrace \sum _{1} ^{n} \lambda _i p _i : \text{each } \lambda _i \geq 0, \sum _{1} ^{n} \lambda _i = 1 \rbrace }$ is shown inductively. 

**Thm**[Caratheodory]: Let ${ T \subseteq \mathbb{R} ^d },$ and ${ z \in \text{conv}(T) }.$ Consider the smallest ${ m }$ such that ${ z }$ can be written as a convex combination of some ${ m }$ points in ${ T }.$ Then ${ m \leq d + 1 }.$   
**Pf**: [Link](https://planetmath.org/proofofcaratheodorystheorem). Since ${ z \in \text{conv}(T) }$ it can be written as ${ z = \sum _{i=1} ^{n} \lambda _i z _i }$ with each ${ \lambda _i \geq 0 ,}$ ${ \sum _{i=1} ^{n} \lambda _i = 1 }.$ If ${ n \leq d +1 }$ we are done, so suppose ${ n > d + 1 }.$ So ${ z _2 - z _1, \ldots, z _n - z _1 \in \mathbb{R} ^d }$ are linearly dependent. So ${ \sum _{i=2} ^{n} \beta _i (z _i - z _1) = 0 }$ for some ${ \beta _i }$s not all ${ 0 }.$ Equivalently ${ \sum _{i=1} ^{n} \gamma _i z _i = 0 }$ with ${ \sum _{i=1} ^{n} \gamma _i = 0 }$ and not all ${ \gamma _i }$ zero. The equations we now have are $${ z = \sum _{i=1} ^{n} \lambda _i z _i , \lambda _i \geq 0, \sum _{1} ^{n} \lambda _i = 1, }$$ $${ \sum _{i =1} ^{n} \gamma _i z _i = 0, \sum _{i=1} ^{n} \gamma _i = 0, \text{ and not all } \gamma _i \text{ are } 0 }.$$    
Focus on the indices ${ \mathscr{I} = \lbrace i \in \lbrace 1 , \ldots, n \rbrace : \gamma _i > 0 \rbrace  },$ a nonempty set. The quantity ${ \lambda = \max _{i \in \mathscr{I}} \frac{\lambda _i}{\gamma _i} }$ lets us write ${  z = \sum _{i =1} ^{n} (\lambda _i - \lambda \gamma _i) z _i  ,}$ and notice this is a convex combination as well. This new convex combination has atleast one coefficient ${ 0 }.$ So roughly, we showed whenever ${ z }$ is a convex combination of ${ n > d + 1 }$ points we can write it as a convex combination with one lesser point, as needed. 








